
# Bigram LLM

PyTorch implementation of Bigram Large Language Models, from scratch. The model trains on a piece of text and generates new text similar to it.
Trainable parameters : 25.37 million
Vocabulary size : 104



## Attention Mechanism

![App Screenshot](https://media.geeksforgeeks.org/wp-content/uploads/20240110170625/Scaled-Dot-Product-and-Multi-Head-Attentions.webp)


## Web Application

![App Screenshot](https://drive.google.com/file/d/1tEE5gI1YoLFTyzLl5C_bD3kQ3tRyeJUB/view?usp=share_link)

